# 嵌入(Embedding)
LLM 能理解是向量化的东西。

优势: 基于语意做检索。传统的检索：基于关键字做匹配。

## 简单实现
1. 将 信息清洗，分段，Embedding 后存入向量数据库。
2. 用户提问时，将 用户提问 Embedding，匹配向量数据库中。
3. 将匹配到到内容，选前几个（看具体 max token 的情况），拼成 Prompt。LLM 组织答案后返回。

细节的优化，对用户的提问 和 LLM 的输出 做了层处理后再返回。

具体可以看：[基于大语言模型构建知识问答系统](https://zhuanlan.zhihu.com/p/627655485)。

## 场景
### 多知识点
提问中包含多知识点时，Embedding-Search 召回精度较低 的问题。比如：
1. 皮蓬、英格利什和布兰德的身高、体重各是多少？
2. 皮蓬、英格利什和布兰德谁的第一位置是 PF？
3. 皮蓬、英格利什和布兰德谁的金徽章数最多？

本地知识建立索引时，通常对单个知识点进行 Embedding；不会也不可能，为不同知识点的排列组合分别制作索引。

解决方案：
1. 识别用户意图，根据意图制定计划，执行计划。通过 命名实体识别 和 槽位填充 实现。
2. 对信息做更多的索引。关键词，主题词检索；对相同知识点建立多级索引；把原始知识库转化为知识图谱。

详细说明：[《LLM+Embedding构建问答系统的局限性及优化方案》](https://zhuanlan.zhihu.com/p/641132245)

## 资源
* [【上集】向量数据库技术鉴赏](https://www.bilibili.com/video/BV11a4y1c7SW/)
* [【下集】向量数据库技术鉴赏](https://www.bilibili.com/video/BV1BM4y177Dk/)
* [LLM+Embedding构建问答系统的局限性及优化方案](https://zhuanlan.zhihu.com/p/641132245)。 作者小虫飞飞的另一篇文章：[基于大语言模型构建知识问答系统](https://zhuanlan.zhihu.com/p/627655485)